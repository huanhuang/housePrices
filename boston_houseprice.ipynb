{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用线性回归预测波士顿房价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归，即学习一个线性方程来拟合特征X与结果Y。  \n",
    "如根据房屋面积x1，房间数量x2，地理位置x3等来预测房屋的价格y。  \n",
    "所以我们要学习一个方程:  \n",
    "$y=w_1x_1+w_2x_2+w_3x_3 + b$  \n",
    "这个方程就是线性回归的$模型函数$，就是最终我们用来预测y值的函数  \n",
    "其中$w_1,w_2,w_3,b$ 就是我们要学习的参数。\n",
    "\n",
    "如何学习$w_1,w_2,w_3,b$ 呢，我们要学到怎样的$w_1,w_2,w_3,b$才能证明这个模型ok呢？  \n",
    "我们的目标是让预测值尽可能地接近真实值。设预测值为$y'$,真实值为y，我们当然是希望|y-$y'$|的值越小越好。  \n",
    "所以我们引入一个代价函数，用来衡量整体的预测值与真实值的整体差距。代价函数如下:  \n",
    "J(W,b) = $\\frac{1}{2m}\\sum_{i=1}^{m}{} (y'^{(i)}-y^{(i)})^2=\\frac{1}{2m}\\sum_{i=1}^{m}{} (W·X^{(i)}+b-y^{(i)})^2$\n",
    "\n",
    "我们的目标就是要最小化J(W,b)。最小化J(W,b)的方法就是梯度下降法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变量说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对所用到的变量做一个统一说明，方便检查。  \n",
    "\n",
    "将$y=w_1x_1+w_2x_2+w_3x_3 + b$  改写为:  \n",
    "   $y=w_0x_0+w_1x_1+w_2x_2+w_3x_3$    \n",
    "   \n",
    "设:  \n",
    "m: 样本个数  \n",
    "n_x：特征维度  \n",
    "θ：($w_0,w_1,w_2,w_3 ...)$  \n",
    "则：  \n",
    "X的shape 为:(m,n_x+1)  \n",
    "y的shape为：(m,1)  \n",
    "θ 的shape = (n_x+1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "3   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "4   7  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     18.7  394.63   2.94  33.4  \n",
       "3     18.7  396.90   5.33  36.2  \n",
       "4     15.2  395.60  12.43  22.9  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data = pd.read_csv(\"data/train.csv\")\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 14)\n",
      "(333, 1)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(pd_data[\"medv\"]).reshape(-1,1)\n",
    "X = np.array(pd_data.drop(columns=[\"medv\"],axis=1))\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X的大小为：(299, 14)\n",
      "tain_y的大小为：(299, 1)\n",
      "test_X的大小为：(34, 14)\n",
      "test_y的大小为：(34, 1)\n"
     ]
    }
   ],
   "source": [
    "#将数据分为训练集和测试集\n",
    "train_X,test_X,train_y,test_y = train_test_split(X,y,test_size = 0.1,random_state = 1)\n",
    "print(f\"train_X的大小为：{train_X.shape}\")\n",
    "print(f\"tain_y的大小为：{train_y.shape}\")\n",
    "print(f\"test_X的大小为：{test_X.shape}\")\n",
    "print(f\"test_y的大小为：{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标准化\n",
    "def nomalize(X,axis):\n",
    "    mean = np.mean(X,axis)\n",
    "    std = np.std(X,axis)\n",
    "    print(mean.shape)\n",
    "    return (X-mean)/std, mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "(299, 15)\n",
      "(34, 15)\n"
     ]
    }
   ],
   "source": [
    "#将数据标准化\n",
    "train_X,mean,std = nomalize(train_X,axis=0)\n",
    "test_X = (test_X-mean)/std\n",
    "\n",
    "#插入一列全为1的表示x0\n",
    "train_X = np.insert(train_X,0,1,axis=1)\n",
    "test_X = np.insert(test_X,0,1,axis=1)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(n):\n",
    "    theta = np.random.randn(n,1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y_,y):\n",
    "    m = y.shape[0]\n",
    "    cost = np.sum(np.square(y_-y))/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数J(·)是一个凸函数。存在极小值。  \n",
    "梯度下降所做的就是在损失函数上沿着导数方向下降，从而靠近极小值。  \n",
    "所以实现梯度下降的步骤为:  \n",
    "1.对θ求偏导:  \n",
    "    $d_θ = \\frac{d_{J(θ)}}{d_θ} = \\frac{1}{m}X·(X·θ-y)$  \n",
    "2.根据$d_θ$更新θ的值:   \n",
    "$θ = θ-αd_θ$  \n",
    "α为学习速率，人为指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_desent(X,y,theta,learning_rate):\n",
    "    m = y.shape[0]\n",
    "    y_ = np.dot(X,theta)\n",
    "    d_theta = np.dot(X.T,y_-y)/m\n",
    "    theta = theta - learning_rate*d_theta\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测\n",
    "使用模型函数进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,theta):\n",
    "    return  np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(train_X,train_y,theta,learning_rate,steps):\n",
    "    costs = []\n",
    "    for step in range(steps):\n",
    "        theta = gradient_desent(train_X,train_y,theta,learning_rate)\n",
    "        y_ = predict(train_X,theta)\n",
    "        loss = compute_cost(y_,train_y)\n",
    "        costs.append(loss)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"\\nAfter {step} step(s),cost is :{loss}\")\n",
    "    return theta,costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算正确率\n",
    "给定一个误差范围，如果预测值与真实值之差在该范围内，则表示预测准确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_pred,y,error_ratio):   \n",
    "    '''\n",
    "    y_pred---预测值\n",
    "    y -- 真实值\n",
    "    error_ratio ---误差范围，相比于真实值的百分比，如0.1，0.05\n",
    "    '''\n",
    "    y = y.reshape(-1,1)\n",
    "    m = y.shape[0]\n",
    "    correct_num = np.sum(np.fabs(y_pred-y) < error_ratio*y)\n",
    "    return correct_num/m\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合到一起，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_X,train_y,test_X,test_y,learning_rate=0.05,steps=1):\n",
    "    m,n_x = train_X.shape\n",
    "    print(learning_rate)\n",
    "    #初始化参数\n",
    "    theta = init_parameters(n_x)\n",
    "    theta,costs = optimizer(train_X,train_y,theta,learning_rate,steps)\n",
    "    \n",
    "    error_ratio = 0.30 # 即误差不能超过30%\n",
    "    print(\"==== 训练集验证 ====\")\n",
    "    y_pred = predict(train_X,theta)\n",
    "    corr_ratio = calc_accuracy(y_pred,train_y,error_ratio)\n",
    "    print(f\"训练集的正确率为：{corr_ratio}\")\n",
    "    \n",
    "    print(\"==== 验证集验证 ====\")\n",
    "    y_pred = predict(test_X,theta)\n",
    "    corr_ratio = calc_accuracy(y_pred,test_y,error_ratio)\n",
    "    print(f\"验证集的正确率为：{corr_ratio}\")\n",
    "    cost = compute_cost(y_pred,test_y)\n",
    "    print(f\"验证集的损失为：{cost}\")\n",
    "\n",
    "    # 绘制损失函数\n",
    "    plt.xlim(0,steps)\n",
    "    plt.plot(costs)\n",
    "    plt.xlabel(\"step(s)\")\n",
    "    plt.ylabel(\"costs\")\n",
    "    plt.show() \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n",
      "\n",
      "After 0 step(s),cost is :230.24825203983994\n",
      "\n",
      "After 100 step(s),cost is :11.363534111692141\n",
      "\n",
      "After 200 step(s),cost is :11.125603518430495\n",
      "\n",
      "After 300 step(s),cost is :11.066212702075525\n",
      "\n",
      "After 400 step(s),cost is :11.050186119615693\n",
      "\n",
      "After 500 step(s),cost is :11.045796164808479\n",
      "\n",
      "After 600 step(s),cost is :11.044589957258454\n",
      "\n",
      "After 700 step(s),cost is :11.044258318698049\n",
      "==== 训练集验证 ====\n",
      "训练集的正确率为：0.8762541806020067\n",
      "==== 验证集验证 ====\n",
      "验证集的正确率为：0.8823529411764706\n",
      "验证集的损失为：11.915018055535366\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = model(train_X,train_y,test_X,test_y,learning_rate=0.09,steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "test_data.head()\n",
    "X_test = np.array(test_data)\n",
    "X_test = (X_test-mean)/std\n",
    "X_test = np.insert(X_test,0,1,axis=1)\n",
    "y_test = predict(X_test,theta)\n",
    "ID = np.array(test_data[\"ID\"]).reshape(-1,1)\n",
    "result = np.hstack((ID,y_test))\n",
    "result_pd = pd.DataFrame(result,columns=[\"ID\",\"medv\"])\n",
    "result_pd[\"ID\"] = result_pd[\"ID\"].astype(int)\n",
    "result_pd.to_csv(\"data/pred_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里使用的是线性回归，线性增长。实际上更应该是增长到一定程度应该放缓。\n",
    "所以更应该选用类似$\\sqrt$z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
